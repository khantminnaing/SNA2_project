{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y485pSKTI0SM"
      },
      "source": [
        "#SNA2 : Social Network Analysis Project\n",
        "\n",
        "This is \"[a] network of books about US politics published around the time of the 2004 presidential election and sold by the online bookseller Amazon.com. Edges between books represent frequent copurchasing of books by the same buyers. The network was compiled by V. Krebs and is unpublished, but can found on Krebs' web site (http://www.orgnet.com/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or4x5w8SI0nQ"
      },
      "source": [
        "##**1. Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qywjI5Z4qOoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf8aa0c-3eac-48ad-ab66-83acd4973842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/Shared drives/SNA group project\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/Shared drives/SNA group project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# change path to the designated google drive folder\n",
        "# otherwise, data will be saved in /content folder which you may have issue locating\n",
        "%cd /content/drive/Shared drives/SNA group project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FBotE57qSZa"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "!pip install ipysigma\n",
        "from ipysigma import Sigma\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "poltext = nx.read_gml('polbooks.gml', label='label')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gYBOaRWJ9SU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Visualization libraries\n",
        "import plotly.express as px\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0u15TAnJ-1h"
      },
      "source": [
        "##**2. Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5mJOMheKIbl"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('polbooks.csv') \n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdjwUK76YgM7"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "labels = {'c': 'Conservative', 'n': 'Neutral', 'l': 'Liberal'}\n",
        "\n",
        "df = df.replace(labels)\n",
        "# create a histogram using Plotly\n",
        "fig = px.histogram(df, x='Value', color='Value',\n",
        "                   color_discrete_map={'Conservative': '#D25565', 'Neutral': '#F0B775', 'Liberal': '#2E94B9'})\n",
        "\n",
        "# update the layout of the figure\n",
        "fig.update_layout(title='Distribution of Political Books on Dataset',\n",
        "                  xaxis_title='Political Orientation',\n",
        "                  yaxis_title='Count',\n",
        "                  xaxis={'categoryorder': 'total descending'},\n",
        "                  height=400, width=500)\n",
        "\n",
        "# show the plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpSbsQARKC5a"
      },
      "source": [
        "## **3. Social Network Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "ne9DbCmRxMHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {'c': 'Conservation', 'l': 'Liberal', 'n': 'Neutral'}\n",
        "\n",
        "# update the 'value' attribute with new labels\n",
        "for node, attr in poltext.nodes(data=True):\n",
        "    old_label = attr['value']\n",
        "    new_label = mapping.get(old_label, old_label)\n",
        "    attr['value'] = new_label"
      ],
      "metadata": {
        "id": "93u9FR3A3Nif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpLwlivC30K8"
      },
      "outputs": [],
      "source": [
        "color_map = {'Conservation': '#D25565', 'Neutral': '#F0B775', 'Liberal': '#2E94B9'}\n",
        "\n",
        "\n",
        "Sigma(poltext,node_label='label',node_size=poltext.degree(), node_color=\"value\", node_border_color_from=\"node\", node_color_palette=color_map)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sigma(poltext, node_metrics=[\"louvain\"], node_color=\"louvain\")\n",
        "\n",
        "# Renaming the target attribute\n",
        "Sigma(poltext, node_metrics={\"community\": \"louvain\"}, node_color=\"community\")\n",
        "\n",
        "# Passing custom parameters\n",
        "Sigma(\n",
        "  poltext,\n",
        "  node_metrics={\"community\": {\"name\": \"louvain\", \"resolution\": 1}},\n",
        "  node_color=\"community\", node_size=poltext.degree(), node_border_color_from=\"node\"\n",
        ")"
      ],
      "metadata": {
        "id": "vjzZCwL0j5SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adcMqzhSci_V"
      },
      "source": [
        "### 3.1      Degree Centrality\n",
        "\n",
        "This metric measures the number of connections (or edges) each node (or book) has. In the context of this network, books with high degree centrality would be those that were frequently copurchased with many other books.\n",
        "\n",
        "https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.degree_centrality.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Urve0ZBUat-G"
      },
      "outputs": [],
      "source": [
        "#Calculate Degree Centrality\n",
        "degree_centrality = nx.degree_centrality(poltext)\n",
        "\n",
        "top_books = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "for book, centrality in top_books:\n",
        "    print(f'{book}: {centrality}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W3ZnQ9IbBp9"
      },
      "outputs": [],
      "source": [
        "# add a new column to the DataFrame with the prices from the dictionary\n",
        "df['degree_centrality'] = df['Label'].map(degree_centrality)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Otahvw9rbdOC"
      },
      "outputs": [],
      "source": [
        "# sort the DataFrame by degree centrality in descending order and select the top 10 rows\n",
        "top_3_degree_centrality = df.sort_values(by='degree_centrality', ascending=False).head(3)\n",
        "\n",
        "# count the number of points in each category within the top 10\n",
        "category_counts = top_3_degree_centrality['Value'].value_counts()\n",
        "\n",
        "# print the category counts\n",
        "print(category_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycg69KYAay_L"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(top_3_degree_centrality, x='Value', color='Value',\n",
        "                   color_discrete_map={'Conservative': '#D25565', 'Neutral': '#F0B775', 'Liberal': '#2E94B9'})\n",
        "\n",
        "# update the layout of the figure\n",
        "fig.update_layout(title='Top 3 Political Books on Amazon with Highest Degree Centrality',\n",
        "                  xaxis_title='Political Orientation',\n",
        "                  yaxis_title='Count',\n",
        "                  xaxis={'categoryorder': 'total descending'},\n",
        "                  height=400, width=700)\n",
        "\n",
        "# show the plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhzGJGMQNrxi"
      },
      "outputs": [],
      "source": [
        "N_mis=len(poltext.nodes())\n",
        "E_mis=len(poltext.edges())\n",
        "N_mis,E_mis,E_mis/N_mis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSK4fxTSNjsn"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from networkx.readwrite import gml\n",
        "G = nx.watts_strogatz_graph(n = N_mis, k = 3, p = 0.05)\n",
        "pos = nx.circular_layout(G)\n",
        "plt.figure(figsize = (12, 12))\n",
        "Sigma(G, node_label='label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Lbm6QTrdynT"
      },
      "source": [
        "### 3.2      betweenness_centrality\n",
        "\n",
        "This metric measures the extent to which a node lies on the shortest paths between other nodes in the network. In the context of this network, books with high betweenness centrality would be those that were frequently copurchased with other books that were not necessarily directly connected to each other.\n",
        "\n",
        "https://networkx.org/documentation/stable/auto_examples/algorithms/plot_betweenness_centrality.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x99kbjJ5dyne"
      },
      "outputs": [],
      "source": [
        "#Calculate Betweeness Centrality\n",
        "betweenness_centrality = nx.betweenness_centrality(poltext)\n",
        "\n",
        "top_books_betweeness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "for book, centrality in top_books:\n",
        "    print(f'{book}: {centrality}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnNoJoHReTop"
      },
      "outputs": [],
      "source": [
        "betweenness_centrality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_cw8tVcdynf"
      },
      "outputs": [],
      "source": [
        "# add a new column to the DataFrame with the prices from the dictionary\n",
        "df['betweenness_centrality'] = df['Label'].map(betweenness_centrality)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaYiU_Mxdynf"
      },
      "outputs": [],
      "source": [
        "# sort the DataFrame by degree centrality in descending order and select the top 10 rows\n",
        "top_20_centrality = df.sort_values(by='betweenness_centrality', ascending=False).head(3)\n",
        "\n",
        "# count the number of points in each category within the top 10\n",
        "category_counts = top_20_centrality['Value'].value_counts()\n",
        "\n",
        "# print the category counts\n",
        "print(category_counts)\n",
        "print(top_20_centrality)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKbfw5Ikdynf"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(top_20_centrality, x='Value', color='Value',\n",
        "                   color_discrete_map={'Conservative': '#D25565', 'Neutral': '#F0B775', 'Liberal': '#2E94B9'})\n",
        "\n",
        "# update the layout of the figure\n",
        "fig.update_layout(title='Top 20 Political Books on Amazon with Highest Betweenness Centrality',\n",
        "                  xaxis_title='Political Orientation',\n",
        "                  yaxis_title='Count',\n",
        "                  xaxis={'categoryorder': 'total descending'},\n",
        "                  height=400, width=700)\n",
        "\n",
        "# show the plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRBO9kEef2Ak"
      },
      "source": [
        "### 3.3      Community Detection (Modularity Maximisation)\n",
        "\n",
        "This analysis involves identifying groups of nodes that are more tightly connected to each other than to the rest of the network. In the context of this network, communities could represent clusters of books that were frequently copurchased together, perhaps corresponding to different political ideologies or topics. \n",
        "\n",
        "This section use Modularity Maximisation Algorithm\n",
        "\n",
        "https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.modularity_max.greedy_modularity_communities.html#networkx.algorithms.community.modularity_max.greedy_modularity_communities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_mi4hjxf_8a"
      },
      "outputs": [],
      "source": [
        "import community\n",
        "\n",
        "community_greedy_modularity = nx.community.greedy_modularity_communities(poltext, weight=None, resolution=1, cutoff=1, best_n=None)\n",
        "community_greedy_modularity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMiDTgdWjPQZ"
      },
      "outputs": [],
      "source": [
        "community_list =[]\n",
        "for i in community_greedy_modularity:\n",
        "  list_item = list(i)\n",
        "  community_list.append(list_item)\n",
        "community_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrFcGNhmkt5D"
      },
      "outputs": [],
      "source": [
        "df_community = pd.DataFrame\n",
        "community_1 = community_list[0]\n",
        "community_2 = community_list[1]\n",
        "community_3 = community_list[2]\n",
        "community_4 = community_list[3]\n",
        "\n",
        "book_list = []\n",
        "for i in community_1:\n",
        "  book_list.append(i)\n",
        "for i in community_2:\n",
        "  book_list.append(i)\n",
        "for i in community_3:\n",
        "  book_list.append(i)\n",
        "for i in community_4:\n",
        "  book_list.append(i)\n",
        "\n",
        "print(len(book_list))\n",
        "\n",
        "community_dict = {}\n",
        "\n",
        "for item in book_list:\n",
        "        if item in community_1:\n",
        "            community_dict[item] = 1\n",
        "        if item in community_2:\n",
        "            community_dict[item] = 2\n",
        "        if item in community_3:\n",
        "            community_dict[item] = 3\n",
        "        if item in community_4:\n",
        "            community_dict[item] = 4\n",
        "\n",
        "\n",
        "\n",
        "print(community_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNZndMv3qWQu"
      },
      "outputs": [],
      "source": [
        "df['communtiy_modularity'] = df['Label'].map(community_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "OUFMmo-Dr3sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_counts = df['communtiy_modularity'].value_counts()\n",
        "\n",
        "# print the category counts\n",
        "print(category_counts)"
      ],
      "metadata": {
        "id": "a70ZDES2sB00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(df, x='communtiy_modularity', color='Value', barmode='group',\n",
        "            color_discrete_map={'Conservative': '#D25565', 'Neutral': '#F0B775', 'Liberal': '#2E94B9'})\n",
        "\n",
        "# update the layout of the figure\n",
        "fig.update_layout(title='Community Detection of Political Books on Amazon with Modularity Maximisation',\n",
        "                  xaxis_title='Community',\n",
        "                  yaxis_title='Count',\n",
        "                  xaxis={'categoryorder': 'total descending'},\n",
        "                  height=400, width=900)\n",
        "\n",
        "# show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "me_3WMigsXQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-lT6I-zt94_"
      },
      "source": [
        "### 3.4      Community Detection (Louvain Algorithm)\n",
        "\n",
        "This analysis involves identifying groups of nodes that are more tightly connected to each other than to the rest of the network. In the context of this network, communities could represent clusters of books that were frequently copurchased together, perhaps corresponding to different political ideologies or topics. \n",
        "\n",
        "This section use Louvain Algorithm \n",
        "\n",
        "https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.louvain.louvain_communities.html#networkx.algorithms.community.louvain.louvain_communities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfRrrROst95N"
      },
      "outputs": [],
      "source": [
        "import community\n",
        "\n",
        "community_louvain= nx.community.louvain_communities(poltext, weight=None, resolution=2, threshold=1e-07, seed=None)\n",
        "\n",
        "community_louvain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pNaxpnVt95N"
      },
      "outputs": [],
      "source": [
        "community_list =[]\n",
        "for i in community_louvain:\n",
        "  list_item = list(i)\n",
        "  community_list.append(list_item)\n",
        "community_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70FeJviIt95N"
      },
      "outputs": [],
      "source": [
        "df_community = pd.DataFrame\n",
        "community_1 = community_list[0]\n",
        "community_2 = community_list[1]\n",
        "community_3 = community_list[2]\n",
        "community_4 = community_list[3]\n",
        "\n",
        "book_list = []\n",
        "for i in community_1:\n",
        "  book_list.append(i)\n",
        "for i in community_2:\n",
        "  book_list.append(i)\n",
        "for i in community_3:\n",
        "  book_list.append(i)\n",
        "for i in community_4:\n",
        "  book_list.append(i)\n",
        "print(len(book_list))\n",
        "community_dict = {}\n",
        "\n",
        "for item in book_list:\n",
        "        if item in community_1:\n",
        "            community_dict[item] = 1\n",
        "        if item in community_2:\n",
        "            community_dict[item] = 2\n",
        "        if item in community_3:\n",
        "            community_dict[item] = 3\n",
        "        if item in community_4:\n",
        "            community_dict[item] = 4\n",
        "\n",
        "\n",
        "\n",
        "print(community_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCLS-ie1t95O"
      },
      "outputs": [],
      "source": [
        "df['community_louvain'] = df['Label'].map(community_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "M5qwKrKHt95O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_counts = df['community_louvain'].value_counts()\n",
        "\n",
        "# print the category counts\n",
        "print(category_counts)"
      ],
      "metadata": {
        "id": "gPah7pSit95O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(df, x='community_louvain', color='Value', barmode='group',\n",
        "            color_discrete_map={'Conservative': '#D25565', 'Neutral': '#F0B775', 'Liberal': '#2E94B9'})\n",
        "\n",
        "# update the layout of the figure\n",
        "fig.update_layout(title='Community Detection of Political Books on Amazon with Louvin Community Detection',\n",
        "                  xaxis_title='Community',\n",
        "                  yaxis_title='Count',\n",
        "                  xaxis={'categoryorder': 'total descending'},\n",
        "                  height=400, width=900)\n",
        "\n",
        "# show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "HlSvqAuXt95O"
      },
      "execution_count": null,
      "outputs": []
    },
  
